{
  "Do you really want to delete this prompt?": "你真的想删除这个提示词吗？",
  "Template": "模版",
  "Example": "示例",
  "Set API Key": "设置 API Key",
  "Select a key": "选择外部凭证",
  "or you can use a temporary key": "或者你可以使用一个临时凭证",
  "Choose model": "选择模型",
  "Model Parameters": "模型参数",
  "If an input's value is not specified at runtime, the default value set here will be used": "如果运行时未指定输入值，则将使用此处设置的默认值",
  "These messages will always be used as the starting message in the chat history": "这些消息将始终用作聊天记录中的起始消息",
  "Probability threshold of the nucleus sampling method in the generation process, for example, when the value is 0.8, only the smallest set of most likely tokens whose probabilities add up to 0.8 or more is retained as the candidate set. The value range is (0, 1.0), the larger the value, the higher the randomness of the generation; the smaller the value, the higher the certainty of the generation.": "生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。",
  "The size of the sampling candidate set during generation. For example, when the value is 50, only the top 50 tokens with the highest scores in a single generation are included in the random sampling candidate set. The larger the value, the higher the randomness of the generation; the smaller the value, the higher the certainty of the generation. The default value is 0, which means that the top_k strategy is not enabled, and only the top_p strategy is effective.": "生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。默认不传递该参数，取值为None或当top_k大于100时，表示不启用top_k策略，此时，仅有top_p策略生效。",
  "Whether to generate thinking content.": "是否生成思考内容。",
  "Whether to use a search engine for data enhancement.": "是否参考使用互联网搜索结果。",
  "The random number seed used when generating, the user controls the randomness of the content generated by the model. seed supports unsigned 64-bit integers, with a default value of 1234. When using seed, the model will try its best to generate the same or similar results, but there is currently no guarantee that the results will be exactly the same every time.": "生成时使用的随机数种子，用户控制模型生成内容的随机性。seed支持无符号64位整数，默认值为1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。",
  "Used to control the repeatability when generating models. Increasing repetition_penalty can reduce the duplication of model generation. 1.0 means no punishment.": "用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。",
  "Used to adjust the degree of randomness from sampling in the generated model, the value range is [0, 2), a temperature of 0 will always produce the same output. The higher the temperature, the greater the randomness.": "用于调整生成模型中采样的随机程度，值范围为 [0, 2)，温度为 0 时将始终产生相同的输出。 温度越高，随机性越大。",
  "Sequences where the API will stop generating further tokens.": "停止词集合，用于控制 API 停止生成更多令牌。",
  "The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.": "聊天完成时生成的最大令牌数。 输入标记和生成标记的总长度受到模型上下文长度的限制。",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.": "数字范围在 -2.0 到 2.0 之间。正数值会根据新词汇是否已经出现在文本中来对其进行惩罚，从而提高模型谈论新话题的可能性。",
  "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.": "数字范围在 -2.0 到 2.0 之间。正数值根据新词汇在目前文本中的出现频率来进行惩罚，降低模型逐字重复同一句话的可能性。",
  "Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40)": "降低产生无意义答案的概率。值越高（例如 100）答案就越多样化，值越低（例如 10）答案就越保守。（默认值：40）",
  "The temperature of the model. Increasing the temperature will make the model answer more creatively. (Default: 0.8)": "模型的温度。增加温度将使模型的回答更具创意。（默认值：0.8）",
  "Works together with topK. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9)": "与 topK 配合使用。较高的值（例如 0.95）将产生更多样化的文本，而较低的值（例如 0.5）将产生更集中和保守的文本。（默认值：0.9）",
  "Sets how strongly to penalize repetitions. A higher value (e.g., 1.5) will penalize repetitions more strongly, while a lower value (e.g., 0.9) will be more lenient. (Default: 1.1)": "设置对重复的惩罚力度。值越高（例如 1.5），对重复的惩罚力度就越强，值越低（例如 0.9），惩罚力度就越宽松。（默认值：1.1）",
  "Sets the random number seed to use for generation. Setting this to a specific number will make the model generate the same text for the same prompt. (Default: 0)": "设置用于生成的随机数种子。将其设置为特定数字将使模型针对同一提示生成相同的文本。（默认值：0）",
  "Maximum number of tokens to predict when generating text. (Default: 128, -1 = infinite generation, -2 = fill context)": "生成文本时要预测的最大标记数。（默认值：128，-1 = 无限生成，-2 = 填充上下文）",
  "Sets the size of the context window used to generate the next token. (Default: 2048)": "设置用于生成下一个标记的上下文窗口的大小。（默认值：2048）",
  "Sets the stop sequences to use. When this pattern is encountered the LLM will stop generating text and return. Multiple stop patterns may be set by specifying multiple separate stop parameters in a modelfile.": "设置要使用的停止序列。遇到此模式时，LLM 将停止生成文本并返回。可以通过在模型文件中指定多个单独的停止参数来设置多个停止模式。"
}
